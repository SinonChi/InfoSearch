Мне всегда не дает покоя идея поисковых машин, особенно то, что создатели в начале даже не подозревали о необыкновенных перспективах данной технологии. Я решил на практике изучить, что же это такое – поисковый движок. Назвал его nanorit.com. Но для экспериментов я не брал никакие известные API от Google, а решил создать свой. Для начала я загрузил базу доменов, получилось около 70000 уникальных сайтов. Далее разработал поискового робота, который подключался поочередно к одному сайту и загружал все ссылки с главной страницы, которые относятся к данному сайту. Такое ограничение я сделал, чтобы робот не погряз в дебрях большого сайта, или раскрученного форума. Но, думаю, в дальнейшем оптимизировать алгоритм. Далее я ставлю метку для проиндексированного сайта с датой индексации и перехожу к следующему сайту. Чего я добился на данный момент – в базе находится сейчас около 1.5 млн. документов, причем загружаю я только заголовки, потому что тело документа грузить весьма накладно по ресурсам. База уже занимает 500 Мб на диске, а размещаюсь на простом хостинге, без выделенного сервера. Далее я рассказал про свою идею знакомому кандидату наук, вместе учились. Он мне рассказал про лингвистический анализ. Я решил разбить все заголовки на отдельные слова и составить реестр данных слов и связанную таблицу – в которой для каждого заголовка идет перечисление идентификаторов слов. В итоге получилось слов в индексе 139000, а связок для заголовков 2,184,204. Далее я сделал алгоритм поиска по данному индексу, но результат оказался хуже, чем если просто искать через like ‘%keyword%’, поэтому я решил пока не развивать алгоритм в эту сторону. Потом я решил проверить интерес пользователей, и добавил рейтинг поисковых запросов, для каждого запроса считаю количество обращений. Самое интересное, что поисковые машины тоже начали «кликать», есть опасность что забанят, но яндекс пока индексирует. Сейчас я добавил функцию добавления своего сайта в индекс, и также пользователи проявили интерес и регулярно добавляют свои сайты. Какие выводы я получил – не боги горшки обжигают. Вот главный вывод. Думаю сейчас развить идею и приобрести выделенный сервер для поисковика. Ну а далее в планах изучить архитектуру кластерной обработки данных и оптимизировать скорость обработки запросов – сейчас честно говоря, по сравнению с гуглом очень медленно ищет.